{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef4e05-2b7e-49d6-9b9e-0f89de7f9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "L1 Density Analysis Around Ligation Points\n",
    "Analysis of L1 element distribution patterns around chromatin ligation points in human genome (hg38)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "# Set working directory and create output directory for plots\n",
    "work_dir = \"your_working_directory\"  # Set your working directory path\n",
    "out_dir = os.path.join(work_dir, \"out\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "os.chdir(work_dir)\n",
    "\n",
    "# Load data\n",
    "print(\"Loading L1 elements...\")\n",
    "te_df = pd.read_csv('hg38_te_filtered.bed', sep='\\t')\n",
    "l1_df = te_df[te_df['repFamily'] == 'L1'].copy()\n",
    "print(f\"Loaded {len(l1_df)} L1 elements\")\n",
    "\n",
    "print(\"Loading LP datasets...\")\n",
    "lp_df1 = pd.read_csv('LP_dataset_1_second_method.csv')\n",
    "lp_df2 = pd.read_csv('LP_dataset_2_second_method.csv')\n",
    "print(f\"Loaded {len(lp_df1)} LPs from dataset 1\")\n",
    "print(f\"Loaded {len(lp_df2)} LPs from dataset 2\")\n",
    "\n",
    "def analyze_l1_density(chrom, point, window=50000, bins=200):\n",
    "    \"\"\"\n",
    "    Analyze L1 density around a given genomic point\n",
    "    \n",
    "    Parameters:\n",
    "    chrom (str): Chromosome name\n",
    "    point (int): Genomic position\n",
    "    window (int): Window size around point (default 50kb)\n",
    "    bins (int): Number of bins for density calculation\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (bin_centers, plus_strand_histogram, minus_strand_histogram)\n",
    "    \"\"\"\n",
    "    window_start = max(0, point - window)\n",
    "    window_end = point + window\n",
    "    \n",
    "    mask = (l1_df['genoName'] == chrom) & \\\n",
    "           (l1_df['genoEnd'] >= window_start) & \\\n",
    "           (l1_df['genoStart'] <= window_end)\n",
    "    \n",
    "    window_l1s = l1_df[mask].copy()\n",
    "    window_l1s['distance'] = ((window_l1s['genoStart'] + window_l1s['genoEnd'])/2 - point)\n",
    "    \n",
    "    plus_strand = window_l1s[window_l1s['strand'] == '+']['distance']\n",
    "    minus_strand = window_l1s[window_l1s['strand'] == '-']['distance']\n",
    "    \n",
    "    bin_edges = np.linspace(-window, window, bins+1)\n",
    "    plus_hist, _ = np.histogram(plus_strand, bins=bin_edges)\n",
    "    minus_hist, _ = np.histogram(minus_strand, bins=bin_edges)\n",
    "    \n",
    "    return bin_edges[:-1], plus_hist, minus_hist\n",
    "\n",
    "def analyze_lps_in_batches(lp_df, dataset_name, batch_size=200, sigma=1):\n",
    "    \"\"\"\n",
    "    Analyze L1 density around LPs in batches\n",
    "    \n",
    "    Parameters:\n",
    "    lp_df (DataFrame): DataFrame with LP coordinates\n",
    "    dataset_name (str): Name for output files\n",
    "    batch_size (int): Number of LPs to process in each batch\n",
    "    sigma (float): Smoothing parameter\n",
    "    \"\"\"\n",
    "    bins = 200\n",
    "    total_plus_lp1 = np.zeros(bins)\n",
    "    total_minus_lp1 = np.zeros(bins)\n",
    "    total_plus_lp2 = np.zeros(bins)\n",
    "    total_minus_lp2 = np.zeros(bins)\n",
    "    count = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    total_lps = len(lp_df)\n",
    "    \n",
    "    for batch_start in range(0, total_lps, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, total_lps)\n",
    "        batch_df = lp_df.iloc[batch_start:batch_end]\n",
    "        \n",
    "        for idx, row in batch_df.iterrows():\n",
    "            try:\n",
    "                # Process LP1\n",
    "                bin_centers, plus_hist, minus_hist = analyze_l1_density(row['chrom'], row['LP1'])\n",
    "                total_plus_lp1 += plus_hist\n",
    "                total_minus_lp1 += minus_hist\n",
    "                \n",
    "                # Process LP2\n",
    "                _, plus_hist, minus_hist = analyze_l1_density(row['chrom'], row['LP2'])\n",
    "                total_plus_lp2 += plus_hist\n",
    "                total_minus_lp2 += minus_hist\n",
    "                \n",
    "                count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {idx}: {e}\")\n",
    "        \n",
    "        # Calculate current averages and save plot\n",
    "        avg_plus_lp1 = gaussian_filter1d(total_plus_lp1 / count, sigma=sigma)\n",
    "        avg_plus_lp2 = gaussian_filter1d(total_plus_lp2 / count, sigma=sigma)\n",
    "        avg_minus_lp1 = gaussian_filter1d(total_minus_lp1 / count, sigma=sigma)\n",
    "        avg_minus_lp2 = gaussian_filter1d(total_minus_lp2 / count, sigma=sigma)\n",
    "        \n",
    "        # Progress update\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"\\nProcessed {count}/{total_lps} LPs ({(count/total_lps*100):.1f}%)\")\n",
    "        print(f\"Time elapsed: {timedelta(seconds=int(elapsed_time))}\")\n",
    "        \n",
    "        # Save current plot\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "        \n",
    "        ax1.plot(bin_centers, avg_plus_lp1, label='LP1', color='blue')\n",
    "        ax1.plot(bin_centers, avg_plus_lp2, label='LP2', color='lightblue', linestyle='--')\n",
    "        ax1.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "        ax1.set_title(f'L1 Plus Strand Density ({dataset_name}, {count} LPs)')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        ax2.plot(bin_centers, avg_minus_lp1, label='LP1', color='red')\n",
    "        ax2.plot(bin_centers, avg_minus_lp2, label='LP2', color='pink', linestyle='--')\n",
    "        ax2.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "        ax2.set_title('L1 Minus Strand Density')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(out_dir, f'{dataset_name}_batch_{count}.png'))\n",
    "        plt.close()\n",
    "\n",
    "# Run analysis\n",
    "print(\"\\nAnalyzing Dataset 1...\")\n",
    "result1 = analyze_lps_in_batches(lp_df1, \"Dataset1\")\n",
    "\n",
    "print(\"\\nAnalyzing Dataset 2...\")\n",
    "result2 = analyze_lps_in_batches(lp_df2, \"Dataset2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
